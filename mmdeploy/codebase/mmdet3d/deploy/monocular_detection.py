# Copyright (c) OpenMMLab. All rights reserved.
from copy import deepcopy
from os import path as osp
import os
from typing import Any, Dict, List, Optional, Sequence, Tuple, Union
import cv2

import mmcv
import numpy as np
import torch
import torch.nn as nn
import mmengine
from mmcv.image import tensor2imgs

from mmengine.dataset import pseudo_collate, Compose
from mmengine.model import BaseDataPreprocessor

from mmdet3d.structures import Box3DMode, get_box_type, Det3DDataSample
from mmdet3d.models import (Base3DDetector, Base3DSegmentor,
                            SingleStageMono3DDetector)
from mmdet3d.visualization.vis_utils import proj_camera_bbox3d_to_img
                        
from torch.utils.data import Dataset

from mmdeploy.codebase.base import BaseTask
from mmdeploy.utils import Task, get_root_logger
from mmdeploy.utils.config_utils import is_dynamic_shape

from .mmdet3d import MMDET3D_TASK

def _get_dataset_metainfo(model_cfg: mmengine.Config):
    """Get metainfo of dataset.

    Args:
        model_cfg Config: Input model Config object.

    Returns:
        list[str]: A list of string specifying names of different class.
    """

    for dataloader_name in [
            'test_dataloader', 'val_dataloader', 'train_dataloader'
    ]:
        if dataloader_name not in model_cfg:
            continue
        dataloader_cfg = model_cfg[dataloader_name]
        dataset_cfg = dataloader_cfg.dataset
        if 'metainfo' in dataset_cfg:
            return dataset_cfg.metainfo
    return None

bbox_palettes = [
    (255, 158, 0),  # Orange
    (255, 99, 71),  # Tomato
    (255, 140, 0),  # Darkorange
    (255, 127, 80),  # Coral
    (233, 150, 70),  # Darksalmon
    (220, 20, 60),  # Crimson
    (255, 61, 99),  # Red
    (0, 0, 230),  # Blue
    (47, 79, 79),  # Darkslategrey
    (112, 128, 144),  # Slategrey
]

@MMDET3D_TASK.register_module(Task.MONOCULAR_DETECTION.value)
class MonocularDetection(BaseTask):

    def __init__(self, model_cfg: mmengine.Config, deploy_cfg: mmengine.Config,
                 device: str):
        super().__init__(model_cfg, deploy_cfg, device)

    def build_backend_model(self,
                           model_files: Sequence[str] = None,
                           **kwargs) -> torch.nn.Module:
        """Initialize backend model.

        Args:
            model_files (Sequence[str]): Input model files.
        Returns:
            nn.Module: An initialized backend model.
        """
        from .monocular_detection_model import build_monocular_detection_model

        data_preprocessor = deepcopy(
            self.model_cfg.model.get('data_preprocessor', {}))
        data_preprocessor.setdefault('type', 'mmdet3D.Det3DDataPreprocessor')

        model = build_monocular_detection_model(
            model_files, 
            self.model_cfg, 
            self.deploy_cfg, 
            device=self.device,
            data_preprocessor=data_preprocessor)
        model = model.to(self.device)
        return model

    def build_pytorch_model(
        self,
        model_checkpoint: Optional[str] = None,
        cfg_options: Optional[Dict] = None,
        **kwargs) -> torch.nn.Module:
        """Initialize torch model.

        Args:
            model_checkpoint (str): The checkpoint file of torch model,
                defaults to `None`.
            cfg_options (dict): Optional config key-pair parameters.
        Returns:
            nn.Module: An initialized torch model generated by other OpenMMLab
                codebases.
        """
        from mmdet3d.apis import init_model
        device = self.device
        model = init_model(self.model_cfg, model_checkpoint, device)
        return model.eval()

    def create_input(self,
                     img: Union[str, np.ndarray],
                     input_shape: Sequence[int] = None,
                     data_preprocessor: Optional[BaseDataPreprocessor] = None) \
            -> Tuple[Dict, torch.Tensor]:
        """Create input for detector.

        Args:
            pcd (str): Input pcd file path.
        Returns:
            tuple: (data, img), meta information for the input image and input.
        """
        cfg = self.model_cfg
        test_pipeline = cfg.test_pipeline
        if isinstance(img, np.ndarray):
            test_pipeline[0].type = 'mmdet3d.LoadImageFromNDArray'

        test_pipeline = deepcopy(test_pipeline)
        test_pipeline = Compose(test_pipeline)

        box_type_3d, box_mode_3d = get_box_type(cfg.test_dataloader.dataset.box_type_3d)
        assert box_mode_3d == Box3DMode.CAM

        ann_file = self.deploy_cfg.codebase_config.ann_file
        data_infos = mmengine.load(ann_file)
        assert len(data_infos['images']) == 1

        img_info = data_infos['images'][0]

        if img_info.get('img', None) is not None:
            img_info.pop('img')
        if img_info.get('img_path', None) is not None:
            img_info.pop('img_path')

        mono_img_info = {f'{img_info["cam_type"]}': img_info}

        data = dict(
            images=mono_img_info,
            box_type_3d=box_type_3d,
            box_mode_3d=box_mode_3d)

        if isinstance(img, np.ndarray):
            data['img'] = img
            data['img_id'] = 0
        else:
            img_info['img_path'] = img
            img_info['img_id'] = 0

        data = test_pipeline(data)

        data = pseudo_collate([data])

        if data_preprocessor is not None:
            data = data_preprocessor(data, False)
            assert 'inputs' in data
            inputs = data['inputs']['imgs']
        else:
            inputs = data['inputs']

        cam2img = [torch.tensor(data['data_samples'][0].metainfo['cam2img'])]
        cam2img_inverse = [torch.inverse(cam2img[0])]
        data['inputs']['cam2img'] = cam2img
        data['inputs']['cam2img_inverse'] = cam2img_inverse 

        return data, tuple([inputs] + cam2img + cam2img_inverse)

    def draw_bboxes(
        self, 
        image: np.ndarray,
        result: Det3DDataSample,
        alpha: Union[int, float] = 0.4,
        line_widths: Union[int, float, List[Union[int, float]]] = 2):
        """Set the image to draw.

        Args:
            image (np.ndarray): The image to draw.
        """
        assert image is not None
        image = image.astype('uint8')

        bboxes_3d = result.pred_instances_3d.bboxes_3d 
        labels_3d = result.pred_instances_3d.labels_3d
        input_meta = result.metainfo

        corners_2d = proj_camera_bbox3d_to_img(bboxes_3d, input_meta)

        # Color
        img_size = image.shape[:2][::-1]  # (width, height)
        edge_colors = [bbox_palettes[label] for label in labels_3d]
        for color in edge_colors:
            assert len(color) == 3
            for channel in color:
                assert 0 <= channel <= 255
            color = [channel / 255 for channel in color]

        valid_point_idx = (corners_2d[..., 0] >= 0) & \
            (corners_2d[..., 0] <= img_size[0]) & \
            (corners_2d[..., 1] >= 0) & (corners_2d[..., 1] <= img_size[1])
        valid_bbox_idx = valid_point_idx.sum(axis=-1) >= 4
        corners_2d = corners_2d[valid_bbox_idx]
        filter_edge_colors = []
        filter_edge_colors_norm = []
        for i, color in enumerate(edge_colors):
            if valid_bbox_idx[i]:
                filter_edge_colors.append(color)
        edge_colors = filter_edge_colors

        overlay = image.copy()
        for color, corner_2d in zip(edge_colors, corners_2d):
            corner_2d = corner_2d.astype(np.int32)
            front = corner_2d[4:]
            rear = corner_2d[:4]
            cv2.fillPoly(overlay, [front], color=color)
            cv2.polylines(overlay, [rear], isClosed=True, color=color, thickness=line_widths)
            for i in range(4):
                cv2.line(
                    overlay, 
                    tuple(front[i]), 
                    tuple(rear[i]), color=color, 
                    thickness=line_widths)

        drawed_image = cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)
        return drawed_image

    def visualize(
        self,
        image: Union[str, np.ndarray],
        result: list,
        output_file: str,
        window_name: str = '',
        show_result: bool = False,
        draw_gt: bool = False,
        **kwargs):
        """visualize backend output.

        Args:
            image (Union[str, np.ndarray]): pcd file path
            result (list): output bbox, score and type
            output_file (str): the directory to save output
            window_name (str, optional): display window name
            show_result (bool, optional): show result or not.
                Defaults to False.
            draw_gt (bool, optional): show gt or not. Defaults to False.
        """

        cfg = self.model_cfg
        visualizer = super().get_visualizer(window_name, output_file)
        visualizer.dataset_meta = _get_dataset_metainfo(cfg)

        collate_data, inputs = self.create_input(image)
        img = collate_data['inputs']['img'][0]
        data_input = dict(img=img)

        visualizer.add_datasample(
            window_name,
            data_input,
            data_sample=result,
            draw_gt=draw_gt,
            show=show_result,
            wait_time=0,
            out_file=output_file,
            vis_task='mono_det')

    def get_model_name(self) -> str:
        """Get the model name.

        Return:
            str: the name of the model.
        """
        raise NotImplementedError

    def get_tensor_from_input(self, input_data: Dict[str, Any],
                              **kwargs) -> torch.Tensor:
        """Get input tensor from input data.

        Args:
            input_data (dict): Input data containing meta info and image
                tensor.
        Returns:
            torch.Tensor: An image in `Tensor`.
        """
        raise NotImplementedError

    def get_partition_cfg(partition_type: str, **kwargs) -> Dict:
        """Get a certain partition config for mmdet.

        Args:
            partition_type (str): A string specifying partition type.
        Returns:
            dict: A dictionary of partition config.
        """
        raise NotImplementedError

    def get_postprocess(self) -> Dict:
        """Get the postprocess information for SDK.

        Return:
            dict: Composed of the postprocess information.
        """
        raise NotImplementedError

    def get_preprocess(self) -> Dict:
        """Get the preprocess information for SDK.

        Return:
            dict: Composed of the preprocess information.
        """
        raise NotImplementedError
