# Copyright (c) OpenMMLab. All rights reserved.
from copy import deepcopy
from os import path as osp
import os
from typing import Any, Dict, List, Optional, Sequence, Tuple, Union

import mmcv
import numpy as np
import torch
import torch.nn as nn
import mmengine
from mmcv.image import tensor2imgs

from mmengine.dataset import pseudo_collate, Compose
from mmengine.model import BaseDataPreprocessor

from mmdet3d.structures import Box3DMode, get_box_type, Det3DDataSample
from mmdet3d.models import (Base3DDetector, Base3DSegmentor,
                            SingleStageMono3DDetector)
from torch.utils.data import Dataset

from mmdeploy.codebase.base import BaseTask
from mmdeploy.utils import Task, get_root_logger
from mmdeploy.utils.config_utils import is_dynamic_shape

from .mmdet3d import MMDET3D_TASK


def _get_dataset_metainfo(model_cfg: mmengine.Config):
    """Get metainfo of dataset.

    Args:
        model_cfg Config: Input model Config object.

    Returns:
        list[str]: A list of string specifying names of different class.
    """

    for dataloader_name in [
            'test_dataloader', 'val_dataloader', 'train_dataloader'
    ]:
        if dataloader_name not in model_cfg:
            continue
        dataloader_cfg = model_cfg[dataloader_name]
        dataset_cfg = dataloader_cfg.dataset
        if 'metainfo' in dataset_cfg:
            return dataset_cfg.metainfo
    return None


@MMDET3D_TASK.register_module(Task.MONOCULAR_DETECTION.value)
class MonocularDetection(BaseTask):

    def __init__(self, model_cfg: mmengine.Config, deploy_cfg: mmengine.Config,
                 device: str):
        super().__init__(model_cfg, deploy_cfg, device)

    def build_backend_model(self,
                           model_files: Sequence[str] = None,
                           **kwargs) -> torch.nn.Module:
        """Initialize backend model.

        Args:
            model_files (Sequence[str]): Input model files.
        Returns:
            nn.Module: An initialized backend model.
        """
        from .monocular_detection_model import build_monocular_detection_model

        data_preprocessor = deepcopy(
            self.model_cfg.model.get('data_preprocessor', {}))
        data_preprocessor.setdefault('type', 'mmdet3D.Det3DDataPreprocessor')

        model = build_monocular_detection_model(
            model_files, 
            self.model_cfg, 
            self.deploy_cfg, 
            device=self.device,
            data_preprocessor=data_preprocessor)
        model = model.to(self.device)
        return model

    def build_pytorch_model(
        self,
        model_checkpoint: Optional[str] = None,
        cfg_options: Optional[Dict] = None,
        **kwargs) -> torch.nn.Module:
        """Initialize torch model.

        Args:
            model_checkpoint (str): The checkpoint file of torch model,
                defaults to `None`.
            cfg_options (dict): Optional config key-pair parameters.
        Returns:
            nn.Module: An initialized torch model generated by other OpenMMLab
                codebases.
        """
        from mmdet3d.apis import init_model
        device = self.device
        model = init_model(self.model_cfg, model_checkpoint, device)
        return model.eval()

    def create_input(self,
                     img: Union[str, np.ndarray],
                     input_shape: Sequence[int] = None,
                     data_preprocessor: Optional[BaseDataPreprocessor] = None) \
            -> Tuple[Dict, torch.Tensor]:
        """Create input for detector.

        Args:
            pcd (str): Input pcd file path.
        Returns:
            tuple: (data, img), meta information for the input image and input.
        """
        cfg = self.model_cfg
        test_pipeline = cfg.test_pipeline
        if isinstance(img, np.ndarray):
            test_pipeline[0].type = 'mmdet3d.LoadImageFromNDArray'

        test_pipeline = deepcopy(test_pipeline)
        test_pipeline = Compose(test_pipeline)

        box_type_3d, box_mode_3d = get_box_type(cfg.test_dataloader.dataset.box_type_3d)
        assert box_mode_3d == Box3DMode.CAM

        ann_file = self.deploy_cfg.codebase_config.ann_file
        data_infos = mmengine.load(ann_file)
        assert len(data_infos['images']) == 1

        img_info = data_infos['images'][0]

        if img_info.get('img', None) is not None:
            img_info.pop('img')
        if img_info.get('img_path', None) is not None:
            img_info.pop('img_path')

        mono_img_info = {f'{img_info["cam_type"]}': img_info}

        data = dict(
            images=mono_img_info,
            box_type_3d=box_type_3d,
            box_mode_3d=box_mode_3d)

        if isinstance(img, np.ndarray):
            data['img'] = img
            data['img_id'] = 0
        else:
            img_info['img_path'] = img
            img_info['img_id'] = 0

        data = test_pipeline(data)

        data = pseudo_collate([data])

        if data_preprocessor is not None:
            data = data_preprocessor(data, False)
            assert 'inputs' in data
            inputs = data['inputs']['imgs']
        else:
            inputs = data['inputs']

        cam2img = [torch.tensor(data['data_samples'][0].metainfo['cam2img'])]
        cam2img_inverse = [torch.inverse(cam2img[0])]
        data['inputs']['cam2img'] = cam2img
        data['inputs']['cam2img_inverse'] = cam2img_inverse 

        return data, tuple([inputs] + cam2img + cam2img_inverse)

    def draw_bboxes(
        self, 
        image: Union[str, np.ndarray],
        result: Det3DDataSample,
    ):
        cfg = self.model_cfg
        visualizer = super().get_visualizer(name="a_random_value", save_dir=None)  
        visualizer.dataset_meta = _get_dataset_metainfo(cfg)
        palette = visualizer.dataset_meta.get('palette', None)

        if isinstance(image, str):
            collate_data, inputs = self.create_input(image)
            img = collate_data['inputs']['img'][0]
            data_input = dict(img=img)
        else:
            data_input = dict(img=image)
        if 'pred_instances_3d' in result:
            pred_instances_3d = result.pred_instances_3d
            pred_data_3d = visualizer._draw_instances_3d(
                data_input,
                pred_instances_3d,
                result.metainfo,
                vis_task='mono_det',
                show_pcd_rgb=False,
                palette=palette)
            if pred_data_3d is not None:
                drawn_img_3d = pred_data_3d['img']
                return drawn_img_3d
            else:
                return data_input['img']
        else:
            return data_input['img']


    def visualize(
        self,
        image: Union[str, np.ndarray],
        result: list,
        output_file: str,
        window_name: str = '',
        show_result: bool = False,
        draw_gt: bool = False,
        **kwargs):
        """visualize backend output.

        Args:
            image (Union[str, np.ndarray]): pcd file path
            result (list): output bbox, score and type
            output_file (str): the directory to save output
            window_name (str, optional): display window name
            show_result (bool, optional): show result or not.
                Defaults to False.
            draw_gt (bool, optional): show gt or not. Defaults to False.
        """

        cfg = self.model_cfg
        visualizer = super().get_visualizer(window_name, output_file)
        visualizer.dataset_meta = _get_dataset_metainfo(cfg)

        collate_data, inputs = self.create_input(image)
        img = collate_data['inputs']['img'][0]
        data_input = dict(img=img)

        visualizer.add_datasample(
            window_name,
            data_input,
            data_sample=result,
            draw_gt=draw_gt,
            show=show_result,
            wait_time=0,
            out_file=output_file,
            vis_task='mono_det')

    def get_model_name(self) -> str:
        """Get the model name.

        Return:
            str: the name of the model.
        """
        raise NotImplementedError

    def get_tensor_from_input(self, input_data: Dict[str, Any],
                              **kwargs) -> torch.Tensor:
        """Get input tensor from input data.

        Args:
            input_data (dict): Input data containing meta info and image
                tensor.
        Returns:
            torch.Tensor: An image in `Tensor`.
        """
        raise NotImplementedError

    def get_partition_cfg(partition_type: str, **kwargs) -> Dict:
        """Get a certain partition config for mmdet.

        Args:
            partition_type (str): A string specifying partition type.
        Returns:
            dict: A dictionary of partition config.
        """
        raise NotImplementedError

    def get_postprocess(self) -> Dict:
        """Get the postprocess information for SDK.

        Return:
            dict: Composed of the postprocess information.
        """
        raise NotImplementedError

    def get_preprocess(self) -> Dict:
        """Get the preprocess information for SDK.

        Return:
            dict: Composed of the preprocess information.
        """
        raise NotImplementedError
